# pyspark-etl-medallion-architecture

# ğŸ IPL Data Engineering Project

An end-to-end data engineering project analyzing **Indian Premier League (IPL)** data using **Apache Spark (PySpark)** and **Databricks**, following the **Medallion Architecture** (Bronze, Silver, Gold layers).

---

## ğŸš€ Project Overview

This project demonstrates how to build a scalable data pipeline using PySpark on Databricks. The IPL dataset is ingested, cleaned, transformed, and analyzed to extract meaningful insights.

---

## ğŸ§° Technologies Used

- ğŸ”¹ **Apache Spark (PySpark)** â€“ Distributed data processing
- ğŸ”¹ **Databricks** â€“ Cloud-based collaborative platform
- ğŸ”¹ **Medallion Architecture** â€“ Bronze, Silver, and Gold layers
- ğŸ”¹ **Delta Lake** â€“ Data versioning and ACID transactions
- ğŸ”¹ **Pandas, Seaborn, Matplotlib** â€“ Visualization libraries
- ğŸ”¹ **Amazon S3 / DBFS** â€“ Data storage (local or cloud)

---

## ğŸ—ï¸ Architecture

```
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Raw Data  â”‚
                 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
               [ Bronze Layer ]
        Ingest raw CSVs into Delta Lake

                      â”‚
               [ Silver Layer ]
      Data cleaning, filtering, transformation

                      â”‚
               [ Gold Layer ]
    Aggregations, business metrics & insights
```

---

## ğŸ“ Project Structure

```
IPL-Data-Engineering-Project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Original IPL datasets
â”‚   â””â”€â”€ processed/             # Transformed datasets
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ bronze_layer.ipynb     # Raw data ingestion
â”‚   â”œâ”€â”€ silver_layer.ipynb     # Data cleaning & transformation
â”‚   â””â”€â”€ gold_layer.ipynb       # Business-level aggregations
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â””â”€â”€ data_transformation.py
â”œâ”€â”€ visuals/                   # Plots and charts
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ architecture_diagram.png
â””â”€â”€ README.md
```

---

## ğŸ” Key Insights

- ğŸ… **Top Batsmen per Season**
- ğŸ¯ **Most Economical Bowlers in Powerplay**
- ğŸ² **Impact of Toss on Match Outcomes**
- ğŸ“ˆ **Team Win Percentages Across Seasons**
- ğŸ‘‘ **Player vs Player Matchups**

---

## ğŸ“Š Visualizations

- ğŸ“Œ Runs scored per team and season
- ğŸ“Œ Wickets taken by top bowlers
- ğŸ“Œ Batsmen strike rates and averages
- ğŸ“Œ Toss vs win correlation charts
- ğŸ“Œ Team vs team performance graphs

Visuals are generated using `matplotlib` and `seaborn`, and stored under the `visuals/` folder.

---

## âš™ï¸ Getting Started

Follow these steps to set up and run the project:

### ğŸ“¥ 1. Clone the Repository

```bash
git clone https://github.com/yourusername/IPL-Data-Engineering-Project.git
cd IPL-Data-Engineering-Project
```

### ğŸ“¦ 2. Install Dependencies

Make sure you have Python 3.8+ installed. Then, install the required Python libraries:

```bash
pip install -r requirements.txt
```

### ğŸ§  3. Prepare the Dataset

Download the IPL dataset from [Kaggle - IPL Dataset](https://www.kaggle.com/datasets/manasgarg/ipl).

Place the following files inside the `data/raw/` folder:
- `matches.csv`
- `deliveries.csv`

### ğŸ’» 4. Run the Project on Databricks

1. **Launch your Databricks workspace**.
2. **Create a cluster** (recommended: Spark 3.x runtime with Python 3.x).
3. **Upload Notebooks**:
   - Navigate to the `/notebooks` directory of this project.
   - Import the notebooks into your Databricks workspace.
4. **Configure File Paths**:
   - Update any DBFS or local file paths in the notebooks to match your environment.
5. **Execute the Pipeline in Sequence**:
   - âœ… `bronze_layer.ipynb` â€“ Raw data ingestion into the Bronze layer.
   - âœ… `silver_layer.ipynb` â€“ Cleaning and transforming data in the Silver layer.
   - âœ… `gold_layer.ipynb` â€“ Aggregation and insights generation in the Gold layer.

---

## ğŸ’¡ Future Enhancements

- Integrate Power BI / Tableau for dashboarding
- Schedule ETL using Apache Airflow or Databricks Jobs
- Add unit tests for transformations
- Real-time ingestion with Kafka

---

## ğŸ¤ Contributing

Contributions are welcome! Feel free to fork the repo and submit pull requests for improvements or bug fixes.

---
## ğŸ™‹â€â™‚ï¸ Connect with Me

- ğŸ”— [LinkedIn](https://www.linkedin.com/in/your-profile/)
- ğŸ“§ your.email@example.com
